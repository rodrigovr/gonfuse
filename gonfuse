#!/usr/bin/python

import pymongo
import gridfs

import fuse
import stat
import os
import errno
import time

from bson.binary import Binary

conn = pymongo.Connection()
db = conn.gridfs

fuse.fuse_python_api = (0, 2)

BLOCK_SIZE = (4*1024)

class Gonfuse(fuse.Fuse):
	def __init__(self, *args, **kw):
		fuse.Fuse.__init__(self, *args, **kw)
		db.files.ensure_index([ ('parent', 1), ('name', 1) ], unique=True)
		#db.blocks.ensure_index([ ('ref', 1) ])

	def getattr(self, path):
		st = fuse.Stat()

		st.st_mode = 0755	
		st.st_atime = int(time.time())
		st.st_mtime = st.st_atime
		st.st_ctime = st.st_ctime
		st.st_nlink = 1
		st.st_size  = BLOCK_SIZE
		st.st_uid   = 0
		st.st_gid   = 0

		if path == '/':
			st.st_mode |= stat.S_IFDIR	
		else:
			f = db.files.find_one({'name': os.path.basename(path), 
			                       'parent': os.path.dirname(path)})
			if f:
				st.st_mode  = f['mode']
				st.st_atime = f['atime']
				st.st_mtime = f['mtime']
				st.st_ctime = f['ctime']
				st.st_uid   = f['uid']
				st.st_gid   = f['gid']
				st.st_size  = f['size']
			else:
				return -errno.ENOENT

		if st.st_mode & stat.S_IFDIR:
			st.st_nlink = 2 + db.files.find({'parent': path}).count()

		return st

	def readdir(self, path, offset):
		ents = [ '.', '..' ]
		for f in db.files.find({'parent': path}):
			ents.append(f['name'].encode('utf-8'))
		for e in ents:
			yield fuse.Direntry(e)

	def open(self, path, flags):
		ctime = int(time.time())
		try:
			db.files.insert({'name': os.path.basename(path), 
			                 'parent': os.path.dirname(path),
		                         'mode': 0775 | stat.S_IFREG,
			                 'uid': self.GetContext()['uid'],
			                 'gid': self.GetContext()['gid'],
			                 'atime': ctime,
		                         'ctime': ctime,
			                 'mtime': ctime,
			                 'size': 0})
		except pymongo.errors.DuplicateKeyError:
			pass
		except pymongo.errors.PyMongoError:
			return -errno.EIO

	def __read_block(self, f, n):
		try:
			if f['blocks'][n] != 0:
				block = db.blocks.find_one({'_id':f['blocks'][n]})
				return str(block['data'])
			else:
				return [0] * BLOCK_SIZE
		except:
			pass

	def read(self, path, size, offset):
		buf = ''
		f = db.files.find_one({'name': os.path.basename(path), 
			               'parent': os.path.dirname(path)})

		blocks = []
		try:
			blocks = f['blocks']
		except:
			f['blocks'] = blocks

		# unaligned read on first block
		block_n = offset / BLOCK_SIZE
		if offset % BLOCK_SIZE != 0:
			pos = offset - (offset % BLOCK_SIZE) * BLOCK_SIZE
			data = self.__read_block(f, block_n)
			size -= len(data)
			buf += data[pos:]
		
		
		while size > 0 and block_n < len(f['blocks']):
			data = self.__read_block(f, block_n)
			size -= len(data)
			block_n += 1
			buf += data

		# truncate
		return buf[0:size]

	def __write_block(self, f, n, data):
		if len(f['blocks']) == 0: 
			f['blocks'] = [0]
		if f['blocks'][n] == 0:
			f['blocks'][n] = db.blocks.insert({'data':Binary(data)})
		else:
			db.blocks.update({'_id':f['blocks'][n]},
			                 {'$set': {'data':Binary(data)}})

	def write(self, path, buf, offset):
		f = db.files.find_one({'name': os.path.basename(path), 
			               'parent': os.path.dirname(path)})

		blocks = []
		try:
			blocks = f['blocks']
		except:
			f['blocks'] = blocks

		size = len(buf)
		written = 0

		# sparse file support
		block_n = 0
		last_block = 0
		pos = 0
		while block_n < offset / BLOCK_SIZE:
			try:
				last_block = f['blocks'][block_n]
			except:
				f['blocks'][block_n] = 0
				last_block = 0
			pos += BLOCK_SIZE

		# first block			
		if pos < offset:
			data = self.__read_block(f, block_n)
			written = min(size,BLOCK_SIZE)
			data = data[0:offset-pos] + buf[0:written]
			self.__write_block(f, block_n, data)
			

		while written < size:
			part = buf[written:max(size,BLOCK_SIZE)]
			
			# last block
			if len(part) < BLOCK_SIZE:			
				data = self.__read_block(f, block_n)
				data = part + data[len(part):]
				self.__write_block(f, block_n, data)
			else:
				self.__write_block(f, block_n, part)

			block_n += 1
			written += len(part)

		f['size'] = max(f['size'], offset + written)
		db.files.update({'name': os.path.basename(path), 
			         'parent': os.path.dirname(path)},
			        {'$set' : {'blocks': f['blocks'],
			                   'size': f['size'],
			                   'mtime': int(time.time())}})

		return written
	
	def mkdir(self, path, mode):
		ctime = int(time.time())
		try:
			db.files.insert({'name': os.path.basename(path), 
			                 'parent': os.path.dirname(path),
		                         'mode': mode | stat.S_IFDIR,
			                 'uid': self.GetContext()['uid'],
			                 'gid': self.GetContext()['gid'],
			                 'atime': ctime,
		                         'ctime': ctime,
			                 'mtime': ctime,
			                 'size': 4096})
		except pymongo.errors.DuplicateKeyError:
			return -errno.EEXIST
		except pymongo.errors.PyMongoError:
			return -errno.EIO

	def mknod(self, path, mode, dev):
		ctime = int(time.time())
		try:
			db.files.insert({'name': os.path.basename(path), 
			                 'parent': os.path.dirname(path),
		                         'mode': mode | stat.S_IFREG,
			                 'uid': self.GetContext()['uid'],
			                 'gid': self.GetContext()['gid'],
			                 'atime': ctime,
		                         'ctime': ctime,
			                 'mtime': ctime,
			                 'size': 0, 'blocks' : []})
		except pymongo.errors.DuplicateKeyError:
			return -errno.EEXIST
		except pymongo.errors.PyMongoError:
			return -errno.EIO

	def unlink(self, path):
		try:
			f = db.files.find_one({'parent':path})
			if f:
				return -errno.ENOTEMPTY

			try:
				for block in f['blocks']:
					db.blocks.remove({'_id': block})
			except pymongo.errors.PyMongoError:
				return -errno.EIO
			except:
				pass

			db.files.remove({'name': os.path.basename(path), 
			                 'parent': os.path.dirname(path)})
		except pymongo.errors.PyMongoError:
			return -errno.EIO

	def rmdir(self, path):
		self.unlink(path)

	def chmod(self, path, mode):
		pass

	def chown(self, path, uid, gid):
		pass

	def truncate(self, path, offset):
		try:
			f = db.files.find_one({'name': os.path.basename(path), 
			                 'parent': os.path.dirname(path)})

			if not f:
				return -errno.ENOENT

			block_size = (4*1024)
			blocks = offset % block_size
			f['blocks'] = f['blocks'][0:max(blocks,len(f['blocks']))]

			db.files.update({'name': os.path.basename(path), 
			                 'parent': os.path.dirname(path)},
			                {'$set':{'size':offset,
			                         'mtime': int(time.time()),
			                         'blocks': f['blocks']}})
			
		except pymongo.errors.PyMongoError:
			return -errno.EIO


if __name__ == '__main__':
	g = Gonfuse()
	g.parse(errex=1)
	g.main()
